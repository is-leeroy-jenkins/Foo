###### foo
[]()

*A Modular Python Framework for Retrieval-Augmented Pipelines and Agentic Workflows*

<p align="left">
  <a href="https://github.com/is-leeroy-jenkins/Foo/blob/main/LICENSE"><img src="https://img.shields.io/github/license/is-leeroy-jenkins/Foo?logo=opensourceinitiative&label=License" alt="License"></a>
  <a href="https://python.org"><img src="https://img.shields.io/badge/Python-3.9+-blue.svg?logo=python" alt="Python 3.9+"></a>
</p>

---

## ğŸ“š Table of Contents

* [Features](#features)
* [Architecture](#architecture)
* [Directory Structure](#directory-structure)
* [Installation](#installation)
* [Quick Start](#quick-start)
* [Usage Examples](#usage-examples)
* [Loaders](#loaders)
* [Fetchers](#fetchers)
* [Scrapers](#scrapers)
* [Dependencies](#dependencies)
* [Technical Notes](#technical-notes)
* [License](#license)
* [Acknowledgments](#acknowledgments)

---

## âœ¨ Features

* Modular, pluggable pipeline for document, web, and data retrieval and processing.
* Robust, extensible loaders and fetchers for all common document and web data formats.
* Clean separation of fetch, scrape, load, convert, and write stages.
* Integrates with OpenAI, LangChain, ChromaDB, and advanced document stores.
* Strong type safety and error handling.
* Simple, testable, and extensible codebase.

---

## ğŸ›ï¸ Architecture

```
Fetcher â†’ Scraper â†’ Loader â†’ Converter â†’ Writer
```

Each stage is a pluggable, testable class. The core orchestrator is the `Fetch` pipeline.

---

## ğŸ—‚ï¸ Directory Structure

```
foo/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ core.py
â”œâ”€â”€ data.py
â”œâ”€â”€ fetchers.py
â”œâ”€â”€ loaders.py
â”œâ”€â”€ scrapers.py
â”œâ”€â”€ config.py
â”œâ”€â”€ requirements.txt
```

---

## ğŸ›¡ï¸ Installation

```bash
git clone https://github.com/is-leeroy-jenkins/Foo.git
cd Foo
python -m venv .venv
.venv/bin/pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

```python
from foo.core import Fetch
fetcher = Fetch(model='gpt-4o', db_uri='sqlite:///foo.sqlite', doc_paths=['docs/*.pdf'])
response = fetcher.query_docs("Summarize the uploaded PDFs.")
print(response)
```

---

## ğŸ” Usage Examples

**Fetch Web Page Paragraphs:**

```python
from foo.scrapers import WebExtractor
extractor = WebExtractor()
paragraphs = extractor.scrape_paragraphs("https://example.com")
print(paragraphs)
```

**Load and Chunk a PDF:**

```python
from foo.loaders import PdfLoader
loader = PdfLoader()
doc = loader.load('docs/report.pdf')
chunks = loader.split(doc)
print(chunks)
```

---

## ğŸ“„ Loaders

### ğŸ›°ï¸ Loader

Abstract base class for all loaders; provides document loading and splitting interface.

* `load(path)` â€“ Loads the document from the specified path.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits a loaded document into overlapping text chunks.

---

### ğŸ›°ï¸ CsvLoader

Loads and splits CSV files for tabular data ingestion.

* `load(path)` â€“ Loads and parses a CSV file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits CSV content for batch processing.

---

### ğŸ›°ï¸ PdfLoader

Loads PDF files, supporting robust text extraction and chunking.

* `load(path)` â€“ Loads and extracts text from a PDF document.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits PDF text into manageable chunks.

---

### ğŸ›°ï¸ DocxLoader

Loads and extracts content from DOCX (Word) documents.

* `load(path)` â€“ Loads and parses a DOCX file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits DOCX text for analysis.

---

### ğŸ›°ï¸ HtmlLoader

Loads and parses local HTML documents.

* `load(path)` â€“ Loads HTML content from a file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits HTML body text into chunks.

---

### ğŸ›°ï¸ PptxLoader

Loads and extracts text from PowerPoint (`.pptx`) files.

* `load(path)` â€“ Loads slide contents from a PowerPoint file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits slide text for downstream use.

---

### ğŸ›°ï¸ ExcelLoader

Loads and processes Excel spreadsheets (XLS/XLSX).

* `load(path)` â€“ Loads and reads an Excel file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits spreadsheet content for batch processing.

---

### ğŸ›°ï¸ TextLoader

Loads plain text files, supporting chunked analysis.

* `load(path)` â€“ Loads the content of a text file.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits text file content into chunks.

---

### ğŸ›°ï¸ JsonLoader

Loads structured data from JSON files.

* `load(path)` â€“ Loads and parses JSON data.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits JSON-encoded text as appropriate.

---

### ğŸ›°ï¸ MarkdownLoader

Loads and splits Markdown (`.md`) documents.

* `load(path)` â€“ Loads a Markdown fileâ€™s content.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits Markdown into logical text chunks.

---

### ğŸ›°ï¸ XmlLoader

Loads and parses XML documents.

* `load(path)` â€“ Loads and parses XML content.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits XML text nodes for further use.

---

### ğŸ›°ï¸ ImageLoader

Loads and processes image files for downstream tasks (e.g., OCR, embeddings).

* `load(path)` â€“ Loads an image file.
* `split(doc, chunk=1000, overlap=100)` â€“ Optionally splits or processes image regions.

---

### ğŸ›°ï¸ YouTubeLoader

Loads YouTube video transcripts and metadata.

* `load(path)` â€“ Retrieves transcript/caption text for a given video ID or URL.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits transcript into chunks.

---

### ğŸ›°ï¸ UnstructuredLoader

Flexible loader for mixed-format or â€œmessyâ€ documents.

* `load(path)` â€“ Loads and attempts to parse various unstructured document formats.
* `split(doc, chunk=1000, overlap=100)` â€“ Splits extracted text for processing.

---

## ğŸ›°ï¸ Fetchers

### ğŸ›°ï¸ Fetcher

Abstract base class for all fetchers, defining the core fetch interface.

* `fetch(url, **kwargs)` â€“ Performs a data retrieval request to a specified endpoint.

---

### ğŸ›°ï¸ WebFetcher

Fetches HTML content using `requests` and provides rich methods for extracting text and elements from web pages.

* `fetch(url, time=10)` â€“ Performs an HTTP GET and returns a structured Result.
* `html_to_text(html)` â€“ Converts raw HTML to compact plain text.
* `scrape_paragraphs(uri)` â€“ Extracts all `<p>` text blocks from a page.
* `scrape_lists(uri)` â€“ Extracts all `<li>` text from lists.
* `scrape_tables(uri)` â€“ Flattens all table cell contents.
* `scrape_articles(uri)` â€“ Extracts content from `<article>` tags.
* `scrape_headings(uri)` â€“ Extracts headings (`<h1>`â€“`<h6>`).
* `scrape_divisions(uri)` â€“ Extracts text from `<div>` elements.
* `scrape_sections(uri)` â€“ Extracts text from `<section>` elements.
* `scrape_blockquotes(uri)` â€“ Extracts `<blockquote>` text.
* `scrape_hyperlinks(uri)` â€“ Extracts all hyperlinks (`<a href>`).
* `scrape_images(uri)` â€“ Extracts image sources (`<img src>`).
* `create_schema(function, tool, description, parameters, required)` â€“ Dynamically builds an OpenAI Tool API schema for function calling.

---

### ğŸ›°ï¸ WebCrawler

JavaScript-capable crawler using `crawl4ai` or Playwright, for dynamic content.

* `fetch(url, depth=1, **kwargs)` â€“ Recursively crawls and fetches HTML from linked pages.

---

### ğŸ›°ï¸ StarMap

Fetches celestial map images using coordinates from StarMap.org.

* `fetch_by_coordinates(ra, dec)` â€“ Generates a star map based on right ascension and declination.

---

### ğŸ›°ï¸ ArxivFetcher

Loads arXiv papers via the `ArxivRetriever`, returning results as document objects.

* `fetch(query, **kwargs)` â€“ Retrieves papers matching the specified query.

---

### ğŸ›°ï¸ GoogleDriveFetcher

Loads files from Google Drive using LangChain retrievers.

* `fetch(query, **kwargs)` â€“ Retrieves documents or file metadata from Google Drive.

---

### ğŸ›°ï¸ WikipediaFetcher

Retrieves Wikipedia articles with full metadata support.

* `fetch(query, **kwargs)` â€“ Retrieves article text and metadata for a search term.

---

### ğŸ›°ï¸ NewsFetcher

Fetches news articles using Thenewsapi.com.

* `fetch(query, **kwargs)` â€“ Retrieves news articles based on keyword and category.

---

### ğŸ›°ï¸ GoogleSearch

Uses Google Custom Search API for web search.

* `fetch(query, **kwargs)` â€“ Executes a web search and returns the top results.

---

### ğŸ›°ï¸ GoogleMaps

Integrates with Google Maps for geocoding, address validation, and directions.

* `geocode(address)` â€“ Returns geocoordinates for a given address.
* `directions(origin, destination)` â€“ Retrieves navigation routes.
* `validate(address)` â€“ Validates a given address.

---

### ğŸ›°ï¸ GoogleWeather

Retrieves weather data using Google Weather API.

* `fetch(location)` â€“ Returns weather info for a location.
* `resolve_location(query)` â€“ Performs geocoding to determine a location from a query.

---

### ğŸ›°ï¸ NavalObservatory

Fetches astronomical and time data from the U.S. Naval Observatory.

* `fetch_julian_date()` â€“ Returns current Julian date.
* `fetch_sidereal_time()` â€“ Returns local sidereal time.

---

### ğŸ›°ï¸ SatelliteCenter

Interfaces with NASA SSCWeb for satellite and ground station data.

* `fetch_orbits(satellite, start, end)` â€“ Retrieves orbital tracks for a satellite.
* `fetch_ground_stations()` â€“ Lists ground station metadata.

---

### ğŸ›°ï¸ EarthObservatory

Connects to NASA EONET for global natural event data.

* `fetch_events(count)` â€“ Returns recent global events (fires, storms, volcanoes, etc).
* `fetch_categories()` â€“ Returns the event categories.

---

### ğŸ›°ï¸ GlobalImagery

Pulls satellite imagery from NASA GIBS WMS.

* `fetch_imagery(bbox, date)` â€“ Returns satellite map tiles or images.

---

### ğŸ›°ï¸ NearbyObjects

Retrieves near-Earth object (NEO) and fireball data from JPLâ€™s CNEOS/SSD APIs.

* `fetch_neos(start, end)` â€“ Returns near-Earth object data for date range.
* `fetch_fireballs(start, end)` â€“ Returns fireball events for date range.

---

## ğŸ›°ï¸ Scrapers

### ğŸ›°ï¸ Extractor

Abstract base for HTML â†’ plain-text extraction.

* `raw_html` â€“ Raw HTML content to be extracted.
* `extract` â€“ Extraction method to convert HTML to text.

---

### ğŸ›°ï¸ WebExtractor

Concrete, synchronous extractor using `requests` and BeautifulSoup for HTMLâ†’text extraction.

* `fetch(url, time=10)` â€“ Performs HTTP GET and returns a canonicalized Result.
* `html_to_text(html)` â€“ Converts HTML to compact plain text (scripts/styles removed).
* `scrape_paragraphs(uri)` â€“ Extracts all `<p>` blocks from a page.
* `scrape_lists(uri)` â€“ Extracts `<li>` text from lists.
* `scrape_tables(uri)` â€“ Extracts cell contents from all `<table>` structures.
* `scrape_articles(uri)` â€“ Extracts consolidated text from `<article>` elements.
* `scrape_headings(uri)` â€“ Extracts headings `<h1>`â€“`<h6>`.
* `scrape_divisions(uri)` â€“ Extracts cleaned text from `<div>` blocks.
* `scrape_sections(uri)` â€“ Extracts readable text from `<section>` elements.
* `scrape_blockquotes(uri)` â€“ Extracts text from `<blockquote>` elements.
* `scrape_hyperlinks(uri)` â€“ Extracts all hyperlink hrefs.
* `scrape_images(uri)` â€“ Extracts image references from `<img src="...">`.
* `create_schema(function, tool, description, parameters, required)` â€“ Builds dynamic OpenAI Tool API schema.

---

## ğŸ“¦ Dependencies

| Package           | Purpose/Description          | Link                                                    |
| ----------------- | ---------------------------- | ------------------------------------------------------- |
| beautifulsoup4    | HTML/XML parsing             | [PyPI](https://pypi.org/project/beautifulsoup4/)        |
| requests          | HTTP client                  | [PyPI](https://pypi.org/project/requests/)              |
| playwright        | Headless browser automation  | [PyPI](https://pypi.org/project/playwright/)            |
| langchain         | LLM & RAG framework          | [LangChain](https://python.langchain.com/)              |
| chromadb          | Vector DB for embeddings     | [PyPI](https://pypi.org/project/chromadb/)              |
| pandas            | Data analysis                | [PyPI](https://pypi.org/project/pandas/)                |
| numpy             | Numeric computing            | [PyPI](https://pypi.org/project/numpy/)                 |
| matplotlib        | Visualization                | [PyPI](https://pypi.org/project/matplotlib/)            |
| owslib            | Geospatial Web Services      | [PyPI](https://pypi.org/project/OWSLib/)                |
| astroquery        | Astronomy data               | [PyPI](https://pypi.org/project/astroquery/)            |
| unstructured      | Document parsing             | [Docs](https://unstructured-io.github.io/unstructured/) |
| pytube            | YouTube video download       | [PyPI](https://pypi.org/project/pytube/)                |
| docx2txt          | DOCX text extraction         | [PyPI](https://pypi.org/project/docx2txt/)              |
| pillow            | Image processing             | [PyPI](https://pypi.org/project/Pillow/)                |
| python-pptx       | PowerPoint processing        | [PyPI](https://pypi.org/project/python-pptx/)           |
| PyMuPDF (fitz)    | PDF parsing                  | [PyPI](https://pypi.org/project/PyMuPDF/)               |
| scikit-learn      | Machine learning             | [PyPI](https://pypi.org/project/scikit-learn/)          |
| tiktoken          | OpenAI tokenization          | [PyPI](https://pypi.org/project/tiktoken/)              |
| pyyaml            | YAML file parsing            | [PyPI](https://pypi.org/project/PyYAML/)                |
| tabulate          | Tabular text/markdown output | [PyPI](https://pypi.org/project/tabulate/)              |
| python-dotenv     | Manage .env files            | [PyPI](https://pypi.org/project/python-dotenv/)         |
| typing_extensions | Type hinting support         | [PyPI](https://pypi.org/project/typing-extensions/)     |

---

## âš™ï¸ Technical Notes

* Pluggable, modular pipelineâ€”add new fetchers/loaders by subclassing.
* Type-safety and error handling by design.
* Compatible with CI/CD and production data environments.

---

## ğŸ“ License

MIT License
Copyright Â© 2022â€“2025 Terry D. Eppler

---

## ğŸ™ Acknowledgments

* Project lead: Terry D. Eppler ([terryeppler@gmail.com](mailto:terryeppler@gmail.com))
* Inspired by open-source Python, ML, and LLM communities.

